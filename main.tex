% % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % %
%\documentclass[runningheads]{llncs}
%\documentclass[12pt,letterpaper]{article}
%\documentclass[preprint,12pt]{elsarticle}
%\documentclass{sig-alternate}
\documentclass[10pt,reprint]{sigplanconf}

% https://avandeursen.com/2013/07/10/research-paper-writing-recommendations/


% packages
\usepackage{xspace}
\usepackage{ifthen}
\usepackage{amsbsy}
\usepackage{amssymb}
\usepackage{balance}
\usepackage{booktabs}
\usepackage{graphicx}
\usepackage{multirow}
\usepackage{needspace}
\usepackage{microtype}
\usepackage{bold-extra}
\usepackage{subfig}
\usepackage{wrapfig}
\usepackage{balance}
\balance

% constants
% \newcommand{\Title}{Toward Reducing Waste of Expandable Collections: The Pharo Case}
\newcommand{\Title}{Enhancing the VM Profiler}
%\newcommand{\Title}{The Dark Side of Expandable Collections: The Pharo Case}
\newcommand{\TitleShort}{\Title}
%\newcommand{\Authors}{~~~~}
\newcommand{\Authors}{Sophie Kaleba, Clément Béra, Alexandre Bergel$^3$\\[2 ex]
$^3$Pleiad Lab, DCC, University of Chile}
\newcommand{\AuthorsShort}{}
%\newcommand{\Authors}{Alexandre Bergel, Vanessa Pe\~na}
%\newcommand{\AuthorsShort}{A. Bergel, V. Pe\~na}

% references
%    IEEE camera ready cannot have a bookmark
%\usepackage[colorlinks,bookmarks=false]{hyperref}
\usepackage[colorlinks]{hyperref}
\usepackage[all]{hypcap}
\setcounter{tocdepth}{2}
\hypersetup{
	colorlinks=true,
	urlcolor=black,
	linkcolor=black,
	citecolor=black,
	plainpages=false,
	bookmarksopen=true,
	pdfauthor={\Authors},
	pdftitle={\Title}}

\def\chapterautorefname{Chapter}
\def\appendixautorefname{Appendix}
\def\sectionautorefname{Section}
\def\subsectionautorefname{Section}
\def\figureautorefname{Figure}
\def\tableautorefname{Table}
\def\listingautorefname{Listing}

% source code
\usepackage{xcolor}
\usepackage{textcomp}
\usepackage{listings}
\definecolor{source}{gray}{0.9}
\lstset{
	language={},
	% characters
	tabsize=3,
	upquote=true,
	escapechar={!},
	keepspaces=true,
	breaklines=true,
	alsoletter={\#:},
	breakautoindent=true,
	columns=fullflexible,
	showstringspaces=false,
	basicstyle=\footnotesize\sffamily,
	% background
	frame=single,
    framerule=0pt,
	backgroundcolor=\color{source},
	% numbering
	numbersep=5pt,
	numberstyle=\tiny,
	numberfirstline=true,
	% captioning
	captionpos=b,
	% formatting (html)
	moredelim=[is][\textbf]{<b>}{</b>},
	moredelim=[is][\textit]{<i>}{</i>},
	moredelim=[is][\color{red}\uwave]{<u>}{</u>},
	moredelim=[is][\color{red}\sout]{<del>}{</del>},
	moredelim=[is][\color{blue}\underline]{<ins>}{</ins>}}
\newcommand{\ct}{\lstinline[backgroundcolor=\color{white},basicstyle=\footnotesize\ttfamily]}
\newcommand{\lct}[1]{{\small\tt #1}}

% tikz
% \usepackage{tikz}
% \usetikzlibrary{matrix}
% \usetikzlibrary{arrows}
% \usetikzlibrary{external}
% \usetikzlibrary{positioning}
% \usetikzlibrary{shapes.multipart}
% 
% \tikzset{
% 	every picture/.style={semithick},
% 	every text node part/.style={align=center}}

% proof-reading
\usepackage{xcolor}
\usepackage[normalem]{ulem}
\newcommand{\ra}{$\rightarrow$}
\newcommand{\ugh}[1]{\textcolor{red}{\uwave{#1}}} % please rephrase
\newcommand{\ins}[1]{\textcolor{blue}{\uline{#1}}} % please insert
\newcommand{\del}[1]{\textcolor{red}{\sout{#1}}} % please delete
\newcommand{\chg}[2]{\textcolor{red}{\sout{#1}}{\ra}\textcolor{blue}{\uline{#2}}} % please change
\newcommand{\chk}[1]{\textcolor{ForestGreen}{#1}} % changed, please check

% comments \nb{label}{color}{text}
\newboolean{showcomments}
\setboolean{showcomments}{true}
\ifthenelse{\boolean{showcomments}}
	{\newcommand{\nb}[3]{
		{\colorbox{#2}{\bfseries\sffamily\scriptsize\textcolor{white}{#1}}}
		{\textcolor{#2}{\sf\small$\blacktriangleright$\textit{#3}$\blacktriangleleft$}}}
	 \newcommand{\version}{\emph{\scriptsize$-$Id$-$}}}
	{\newcommand{\nb}[3]{}
	 \newcommand{\version}{}}
\newcommand{\rev}[2]{\nb{Reviewer #1}{red}{#2}}
\newcommand{\ab}[1]{\nb{Alexandre}{blue}{#1}}
\newcommand{\lr}[1]{\nb{Lukas}{pink}{#1}}
\newcommand{\ai}[1]{\nb{Alejandro}{orange}{#1}}
\newcommand{\on}[1]{\nb{Oscar}{olive}{#1}}

% graphics: \fig{position}{percentage-width}{filename}{caption}
\DeclareGraphicsExtensions{.png,.jpg,.pdf,.eps,.gif}
\graphicspath{{figures/}}
\newcommand{\fig}[4]{
	\begin{figure}[#1]
		\centering
		\includegraphics[width=#2\textwidth]{#3}
		\caption{\label{fig:#3}#4}
	\end{figure}}

\newcommand{\largefig}[4]{
	\begin{figure*}[#1]
		\centering
		\includegraphics[width=#2\textwidth]{#3}
		\caption{\label{fig:#3}#4}
	\end{figure*}}
	
\newcommand{\wrapfig}[5]{	
\begin{wrapfigure}{#1}{#2\textwidth}
  \begin{center}
    \includegraphics[width=#3\textwidth]{#4}
  \end{center}
  \caption{\label{fig:#4}#5}
\end{wrapfigure}}

% abbreviations
\newcommand{\ie}{\emph{i.e.,}\xspace}
\newcommand{\eg}{\emph{e.g.,}\xspace}
\newcommand{\etc}{\emph{etc.}\xspace}
\newcommand{\etal}{\emph{et al.}\xspace}

% lists
\newenvironment{bullets}[0]
	{\begin{itemize}}
	{\end{itemize}}

\newcommand{\seclabel}[1]{\label{sec:#1}}
\newcommand{\figlabel}[1]{\label{fig:#1}}
\newcommand{\tablabel}[1]{\label{tab:#1}}
\newcommand{\figref}[1]{Figure~\ref{fig:#1}}
\newcommand{\secref}[1]{Section~\ref{sec:#1}}


%Specialized macros
\pagenumbering{arabic}
\DeclareCaptionType{copyrightbox}
\newcommand{\myparagraph}[1]{\vspace{0.1cm}\noindent \textbf{\textit{#1.}}}
%\journal{Science of Computer Programming}

% \makeatletter
% \let\@copyrightspace\relax
% \makeatother
% 

%double spaced
%\renewcommand{\baselinestretch}{1.5}

\begin{document}

\special{papersize=8.5in,11in}
\setlength{\pdfpageheight}{\paperheight}
\setlength{\pdfpagewidth}{\paperwidth}

\conferenceinfo{OOPSLA '14}{Month d--d, 20yy, City, ST, Country}
\copyrightyear{2014}
\copyrightdata{978-1-nnnn-nnnn-n/yy/mm}
\doi{nnnnnnn.nnnnnnn}


%\begin{frontmatter}
\title{\Title}


\authorinfo{Sophie Kaleba$^1$, Clement Bera$^1$, Alexandre Bergel$^2$}
           {$^1$INRIA- Lille Nord Europe, France\\
             $^2$Pleiad Lab, DCC, University of Chile, Santiago, Chile}
           {}
%\author{\Authors
%}


%\institute{~~}
%\institute{Pleiad Lab, University of Chile}
\maketitle

\begin{abstract}

* A REECRIRE *

Code profiling is critical when it comes to improve the performance of your applications. This applies of course for Smalltalk applications and a lot of different profiling tools are already available, such as MessageTally, GadgetProfiler, VMProfiler. The last one can especially provide significant data to help you tune the virtual machine (VM) settings for performance.
However, this VM profiler is only available on Squeak. [nécessaire? : This is getting critical as the number of Pharo users is growing]. Besides, new optimisations are added to the Just-In-Time (JIT) compiler, that could compromise the relevance of the data provided by this profiler. 

In this paper, we discuss these two problems and then we introduce the VM profiler for Pharo and the solution proposed to keep collecting relevant profiling data despite the enhancements of the JIT.

* A REECRIRE *

\end{abstract}

%\begin{keyword}
%% keywords here, in the form: keyword \sep keyword

%% MSC codes here, in the form: \MSC code \sep code
%% or \MSC[2008] code \sep code (2000 is the default)

%\end{keyword}

%\end{frontmatter}
%: % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % %

\section{Introduction}
%context
%main challenge in general and thus for VMs : performance

\textbf{Even though the technical specs of computers get more and more impressive, performance, both in terms of execution time and XXX, remains a major goal to be pursuied (atroce).
[besoin d'une transition non moisie vers les VM]}
This applies of course to virtualised environments : assuring the performance of the virtual machine (VM) is critical when you aim for overall good performances. These performances can be assessed by metrics such as bytecodes-per-second and sends-per-second [reference : Modern Problems for the Smalltalk VM] 

%Cog - what is it, what are its major features. \textbf{[references]}
Cog is a virtual machine designed for Smalltaltk, and currently used for various Smalltalk-based languages such as Pharo or Squeak. It features (what exactly? JIT, optimisations such as inline-caching...?) [reference - article about the features of cog?]
Aiming for performance, it is crucial to know where the time is spent in the VM during execution : indeed, it helps identifying hotspots and where to tune the VM settings to actually get better results.

These critical informations can be collected by profiling code, to get a precise idea of the program behaviour. Such profiling tools are already available in Smalltalk, like MessageTally and VMProfiler : they provide statistical/graphical reports, showing the methods in which most of the execution time is spent, and how much of this time is spent in garbage collection \textbf{[reference needed]}. However, the VM profiler, unlike MessageTally, provides statistical data about the time spent in the VM, ie. time spent in the JIT-generated methods, and in the GC and interpreter.\\

% problem 
Right now, the VM profiler cannot track down precisely where the time is spent when executing the code generated by the JIT. It can track down in which methods the time is spent, but it cannot track down in which part of those methods the time is spent. For example, let’s say there is a frequently used method with multiple loops. The VM profiler can tell us that most of the time is spent in this method (it is indeed frequently used), but it cannot tell in which loop the time is spent.

This problem is more and more significant as new optimisations are added to the JIT \textbf{[reference needed]}. The development branch of the JIT now features speculative inlining. In this context, the JIT generates a single machine code method for multiple bytecode methods (the method optimised and the inlined methods). The VM profiler shows that most of the time is spent in optimised code, but it is currently not possible to know in which inlined method most of the time is spent. So while we get a faster and more performant VM, we lose the ability to profile it in a relevant way.\\

%solution
To get relevant profiling data again, we have to tweak the VM profiler so it shows where specifically the time is spent in a method. After porting the profiler to Pharo \textbf{[justifier avant pourquoi Pharo? ou juste retirer cette partie]}, we use an API usually used for debugging, that maps machine code pc to bytecode pc. This way, we can tell for each method appearing in the report in which bytecode range most time is spent.


%: % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % %

\section{Problem}

%context/background 
*intro about the profilers in general : 
aim =required for performance, to know where you need to optimise (identifying hotspots)
2 (maybe more) major kinds of profiler : sampling and instrumenting. 
then a quick pros and cons [reference?]	
	
*profiling in Pharo-Smalltalk
In Squeak, 2 (?) profiling tools are available in the image: MessageTally and VM profiler. Both are sampling profilers, but they are not used for the same purpose. MessageTally = image side, VM profiler = vm side.
As we are focused on where the time is spent on the VM-side, let's focus on the VM Profiler :
It is cadenced at 1.3GHz tracking down where the time is spent in the C code of the VM (for the interpreter and the GC) and in the machine code zone (for the code generated by the JIT).
\textbf{(figure très simple sur la cog memory ...?)}
The profiling consists first in gathering samples, ie. instruction pointers, referring to the currently executed function, and then in mapping these samples with the symbols (functions) part of the VM and the external modules it uses. 
\textbf{(figure - focus sur le mapping ? functionSymbol --> sampleBag --> report)}

Besides computing the time spent in the machine code zone, the profiler computes as well the time spent in the C code of the VM and provides data about the memory usage and the different events occurring during the profiling. All the results are available as a statistical report 

	
%problem
*problem : cog optimisations and (pharo) customer requests (talk about the customer request Clément had that needed a vm profiler in Pharo ), that first require to profile on vm-side on Pharo and then, to get precise profiling data to be able to tune vm settings for performance. 
To address this problem, we propose an implementation that take advantage of an API used for debugging, to map machine code pc to bytecode pc, to be able to tell in which bytecode range the time is spent in a method.

*use case

(figure : part of a profiling report showing that case of a similar one ?)


%: % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % %

\section{Solution}
% a few words about the port
% then talk about the profiler optimisation
% - the primitive : what it was doing before, what it does now : what have changed ? (figure)
(added an argument, added a new method in which we do the mapping)
(maybe talking about the API?)
% - implementation (how do we use the results from the modified primitive in the profiler

%: % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % %

\section{Evaluation/Validation}
benchmark

%: % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % %
\section{Related Work}\seclabel{relatedWork}
*messageTally [reference]
description, comparison
*spy [reference]
description, comparison
*gadgetProfiler [reference]
description, comparison
jvisualvm

%: % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % %
\section{Conclusion and Future Work}\seclabel{conclusion}
% windows
% UI

%{\footnotesize \myparagraph{Acknowledgments} We thank 
%Oscar Nierstrasz, 
%Lukas Renggli,
%Eric Tanter, and 
%Renato Cerro 
%for their comments on an early draft of this paper. We also thank Aleksandar Prokopec for his help with Scala collections.}
%: % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % %

%{\small
\bibliographystyle{elsarticle-num}
\bibliography{scg}
%\bibliography{hapao}
%}


%\appendix 
\end{document}

